# day92笔记

### 0.0小拓展

- Python subprocess模块Popen,详细用法见：<https://www.jb51.net/article/142787.htm>

  ```python
  import subprocess
  
  res = subprocess.Popen("ipconfig", shell=True, stdout=subprocess.PIPE,encoding='gbk') # 使用管道
   # 标准输出
  print(res.stdout.read())  #可使用decode('gbk')
  res.stdout.close()  # 关闭
  
  # 以太网适配器 以太网:
  # 
  #    连接特定的 DNS 后缀 . . . . . . . : 
  #    本地链接 IPv6 地址. . . . . . . . : fe80::1c15:c8c0:ac7e:f9bf%20
  #    IPv4 地址 . . . . . . . . . . . . : 192.168.12.52
  #    子网掩码  . . . . . . . . . . . . : 255.255.255.0
  #    默认网关. . . . . . . . . . . . . : 192.168.12.1
  #   ....
  #    ....
  ```




www.baiduai.com 去百度AI官网

用户名：电话号，密码：手机获取

- QBS 每秒钟允许请求次数。



### 1.语音合成文档

- ##### 新建AipSpeech

  - AipSpeech是语音合成的Python SDK客户端，为使用语音合成的开发人员提供了一系列的交互方法。

  - 参考如下代码新建一个AipSpeech：

    ```python
     #tts.py
    from aip import AipSpeech
    
    """你的 APPID API_KEY SECRET_KEY"""
    APP_ID = "16981752"
    API_KEY="GiOTHLnwCyyQ1UZmtGbf1W0G"
    SECRET_KEY="gEGlsqLhbpz0Ev8j5T2YNisyh5yEHWg2"
    
    client =AipSpeech(APP_ID,API_KEY,SECRET_KEY)
    ```
  
    

- ##### 语音合成（TTS）

  - 合成文本长度必须小于1024字节，如果本文长度较长，可以采用多次请求的方式。文本长度不可超过限制举例，要把一段文字合成为语音文件：

    ```python
    result = client.synthesis("你是我的小丫小苹果",'zh',1,{
        'vol':5,#合成音频文件准音量
        'spd':4,#语速 
        'pit':8,#语音音调,
        'per':4,#发音人选择，
    })
     # 识别正确返回语音二进制 错误则返回dict 参照下面错误码
    if not isinstance(result,dict):
        with open("auido.mp3",'wb') as f:
            f.write(result)  #生成MP3文件，将文本装转换mp3
    else:
        print(result)
    ```

    

  - 参数设置

  | 参数 | 类型   | 描述                                                         | 是否必须 |
  | ---- | ------ | ------------------------------------------------------------ | -------- |
  | tex  | String | 合成的文本，使用UTF-8编码， 请注意文本长度必须小于1024字节   | 是       |
  | cuid | String | 用户唯一标识，用来区分用户， 填写机器 MAC 地址或 IMEI 码，长度为60以内 | 否       |
  | spd  | String | 语速，取值0-15，默认为5中语速                                | 否       |
  | pit  | String | 音调，取值0-15，默认为5中语调                                | 否       |
  | vol  | String | 音量，取值0-15，默认为5中音量                                | 否       |
  | per  | String | 发音人选择, 0为女声，1为男声， 3为情感合成-度逍遥，4为情感合成-度丫丫，默认为普通女 | 否       |

- 错误信息：

  - 若请求错误，服务器将返回的JSON文本包含以下参数：
    - **error_code**：错误码。
    - **error_msg**：错误描述信息，帮助理解和解决发生的错误。

  - 错误码：

    | 错误码 | 含义           |
    | ------ | -------------- |
    | 500    | 不支持的输入   |
    | 501    | 输入参数不正确 |
    | 502    | token验证失败  |
    | 503    | 合成后端错误   |

  - 错误示例：

    ```python
    {'err_detail': 'Params error.',
     'err_msg': 'parameter error.',
     'err_no': 501, 'err_subcode': 29, 
     'tts_logid': 1755077095}
    ```



### 2.在线语音识别（ASR）

- 新建、配置AipSpeech与语音合成文档一样。

#### 1.PCM文件转换

- 因baiduAI识别音频只能识别PCM格式。

- 使用一款工具：ffmpeg

- 首先配置环境变量：

  ```
  把ffmpeg文件bin目录加入环境变量
  	G:\人工智能工具包\Tools\ffmpeg\bin
  ```

- 格式转换命令：

  ```
  终端输入：
  	ffmpeg -y  -i audio.wav(被转换音频)  -acodec pcm_s16le -f s16le -ac 1 -ar 16000 audio.pcm(转换后音频)
  ```

- 代码编写：

  ```python
  #识别语音转换pcm音频
  import os
  from aip import AipSpeech
  
  APP_ID = "16981752"
  API_KEY="GiOTHLnwCyyQ1UZmtGbf1W0G"
  SECRET_KEY="gEGlsqLhbpz0Ev8j5T2YNisyh5yEHWg2"
  
  client =AipSpeech(APP_ID,API_KEY,SECRET_KEY)
  
  #读取文件
  def get_file_content(filePath):
      cmd_str = f"ffmpeg -y  -i {filePath}  -acodec pcm_s16le -f s16le -ac 1 -ar 16000 {filePath}.pcm"
      os.system(cmd_str)#通过os模块执行CMD命令：把音频格式转换pcm格式
      with open(f"{filePath}.pcm","rb") as fp:
          return fp.read()
  
  #识别本地文件，将音频格式转换成字典，将音频读成文本
  res = client.asr(get_file_content("auido.mp3"),'pcm',16000,{
      "dev_pid":1536,
  })
  print(res)
  print(res.get("result")[0])
  #{'corpus_no': '6723049259124123090', 'err_msg': 'success.', 'err_no': 0, 'result': ['电脑前的你真好看'], 'sn': '205127170801565331886'}
  #电脑前的你真好看
  ```

  - 参数设置：

    | 参数        | 类型   | 描述                                                         | 是否必须 |
    | ----------- | ------ | ------------------------------------------------------------ | -------- |
    | speech      | Buffer | 建立包含语音内容的Buffer对象, 语音文件的格式，pcm 或者 wav 或者 amr。不区分大小写 | 是       |
    | format      | String | 语音文件的格式，pcm 或者 wav 或者 amr。不区分大小写。推荐pcm文件 | 是       |
    | rate        | int    | 采样率，16000，固定值                                        | 是       |
    | cuid        | String | 用户唯一标识，用来区分用户，填写机器 MAC 地址或 IMEI 码，长度为60以内 | 否       |
    | dev_pid     | Int    | 不填写lan参数生效，都不填写，默认1537（普通话 输入法模型），dev_pid参数见本节开头的表格 | 否       |
    | lan(已废弃) | String | 历史兼容参数，请使用dev_pid。如果dev_pid填写，该参数会被覆盖。语种选择,输入法模型，默认中文（zh）。 中文=zh、粤语=ct、英文=en，不区分大小写。 | 否       |

    **注意：baiduAI官网文档长时间没更新，有些方法需自己实测才行**

    - dev_pid的参数设置

    | dev_pid | 语言                       | 模型       | 是否有标点 | 备注             |
    | ------- | -------------------------- | ---------- | ---------- | ---------------- |
    | 1536    | 普通话(支持简单的英文识别) | 搜索模型   | 无标点     | 支持自定义词库   |
    | 1537    | 普通话(纯中文识别)         | 输入法模型 | 有标点     | 不支持自定义词库 |
    | 1737    | 英语                       |            | 无标点     | 不支持自定义词库 |
    | 1637    | 粤语                       |            | 有标点     | 不支持自定义词库 |
    | 1837    | 四川话                     |            | 有标点     | 不支持自定义词库 |
    | 1936    | 普通话远场                 | 远场模型   | 有标点     | 不支持           |

    - 语音识别返回数据参数详情

    | 参数    | 类型 | 是否一定输出 | 描述                                                         |
    | ------- | ---- | ------------ | ------------------------------------------------------------ |
    | err_no  | int  | 是           | 错误码                                                       |
    | err_msg | int  | 是           | 错误码描述                                                   |
    | sn      | int  | 是           | 语音数据唯一标识，系统内部产生，用于 debug                   |
    | result  | int  | 是           | 识别结果数组，提供1-5 个候选结果，string 类型为识别的字符串， utf-8 编码 |

    - 返回样式：

    ```python
    # 成功返回
    {
        "err_no": 0,
        "err_msg": "success.",
        "corpus_no": "15984125203285346378",
        "sn": "481D633F-73BA-726F-49EF-8659ACCC2F3D",
        "result": ["北京天气"]
    }
    
    # 失败返回
    {
        "err_no": 2000,
        "err_msg": "data empty.",
        "sn": null
    }
    ```

#### 2.错误信息

- 错误返回格式：
  - 若请求错误，服务器将返回JSON文本包含以下参数：
    - error_code :错误码。
    - error_msg:错误描述信息，帮助李杰和解决发生的错误。

- 错误码：

  | 误码 | 用户输入/服务端 | 含义                         | 一般解决方法                                                 |
  | ---- | --------------- | ---------------------------- | ------------------------------------------------------------ |
  | 3300 | 用户输入错误    | 输入参数不正确               | 请仔细核对文档及参照demo，核对输入参数                       |
  | 3301 | 用户输入错误    | 音频质量过差                 | 请上传清晰的音频                                             |
  | 3302 | 用户输入错误    | 鉴权失败                     | token字段校验失败。请使用正确的API_KEY 和 SECRET_KEY生成     |
  | 3303 | 服务端问题      | 语音服务器后端问题           | 请将api返回结果反馈至论坛或者QQ群                            |
  | 3304 | 用户请求超限    | 用户的请求QPS超限            | 请降低识别api请求频率 （qps以appId计算，移动端如果共用则累计） |
  | 3305 | 用户请求超限    | 用户的日pv（日请求量）超限   | 请“申请提高配额”，如果暂未通过，请降低日请求量               |
  | 3307 | 服务端问题      | 语音服务器后端识别出错问题   | 目前请确保16000的采样率音频时长低于30s，8000的采样率音频时长低于60s。如果仍有问题，请将api返回结果反馈至论坛或者QQ群 |
  | 3308 | 用户输入错误    | 音频过长                     | 音频时长不超过60s，请将音频时长截取为60s以下                 |
  | 3309 | 用户输入错误    | 音频数据问题                 | 服务端无法将音频转为pcm格式，可能是长度问题，音频格式问题等。 请将输入的音频时长截取为60s以下，并核对下音频的编码，是否是8K或者16K， 16bits，单声道。 |
  | 3310 | 用户输入错误    | 输入的音频文件过大           | 语音文件共有3种输入方式： json 里的speech 参数（base64后）； 直接post 二进制数据，及callback参数里url。 分别对应三种情况：json超过10M；直接post的语音文件超过10M；callback里回调url的音频文件超过10M |
  | 3311 | 用户输入错误    | 采样率rate参数不在选项里     | 目前rate参数仅提供8000,16000两种，填写4000即会有此错误       |
  | 3312 | 用户输入错误    | 音频格式format参数不在选项里 | 目前格式仅仅支持pcm，wav或amr，如填写mp3即会有此错误         |

### 3.自然语言基础处理

- AipNlp是自然语言处理的Python SDK客户端，为使用自然语言处理的开发人员提供了一系列的交互方法。

  ```
  from aip import AipNlp
  
  """ 你的 APPID AK SK """
  APP_ID = '你的 App ID'
  API_KEY = '你的 Api Key'
  SECRET_KEY = '你的 Secret Key'
  
  client = AipNlp(APP_ID, API_KEY, SECRET_KEY)
  ```

- 短文本相似度：

  - 短文本相似度接口用来判断两个文本的相速度得分

  ```python
  text1 = "浙富股份"
  
  text2 = "万事通自考网"
  
  """ 调用短文本相似度 """
  client.simnet(text1, text2);
  
  """ 如果有可选参数 """
  options = {}
  options["model"] = "CNN"
  
  """ 带参数调用短文本相似度 """
  client.simnet(text1, text2, options)
  ```

  - 短文本相似度，请求参数

  | 参数名称 | 是否必选 | 类型   | 可选值范围   | 说明                                  |
  | :------- | :------- | :----- | :----------- | :------------------------------------ |
  | text_1   | 是       | string |              | 待比较文本1（GBK编码），最大512字节   |
  | text_2   | 是       | string |              | 待比较文本2（GBK编码），最大512字节   |
  | model    | 否       | string | BOW CNN GRNN | 默认为"BOW"，可选"BOW"、"CNN"与"GRNN" |

  - 短文本相似度返回数据：

  ```python
  {
      "log_id": 12345,
      "texts":{
          "text_1":"浙富股份",
          "text_2":"万事通自考网"
      },
      "score":0.3300237655639648 //相似度结果
  },
  ```

  - 短文本相似度请求参数详情

  | 参数    | 类型   | 描述               |
  | :------ | :----- | :----------------- |
  | log_id  | number | 请求唯一标识       |
  | score   | number | 两个文本相似度得分 |
  | texts   | array  | 输入文本           |
  | +text_1 | string | 第一个短文本       |
  | +text_2 | string | 第二个短文本       |

### 4.实现一个简单语音回复

- 示例1：

  ```python
  import os
  from aip import AipSpeech
  from aip import AipNlp
  
  APP_ID = "16981752"
  API_KEY="GiOTHLnwCyyQ1UZmtGbf1W0G"
  SECRET_KEY="gEGlsqLhbpz0Ev8j5T2YNisyh5yEHWg2"
  
  client =AipSpeech(APP_ID,API_KEY,SECRET_KEY)
  nlp_client =AipNlp(APP_ID,API_KEY,SECRET_KEY)#用于匹配文本相似度
  
  
  #1.先做语音识别
  #读取文件
  def get_file_content(filePath):
      cmd_str = f"ffmpeg -y  -i {filePath}  -acodec pcm_s16le -f s16le -ac 1 -ar 16000 {filePath}.pcm"
      os.system(cmd_str)
      with open(f"{filePath}.pcm","rb") as fp:
          return fp.read()
  
  res = client.asr(get_file_content("auido.mp3"),'pcm',16000,{
      "dev_pid":1536,
  })
  #2.拿出语音识别内容的做判断
  msg = "我不知道你在说什么"
  
  #拿出语音识别的做判断
  msg = "我不知道你在说什么"
  
  temp = nlp_client.simnet(res.get("result")[0],"你的名字叫什么")
  temp2 = nlp_client.simnet(res.get("result")[0],"你今年多大了")
  if temp["score"] >= 0.70:
      print(temp["score"])
      msg = "我的名字叫文咏珊"
  
  if temp2["score"]  >= 0.70:
      print(temp2["score"])
      msg = "我今年25岁了"
  
  
  #3.将回复信息合成语音
  result = client.synthesis(msg,'zh',1,{
      'vol':5,#合成音频文件准音量
      'spd':4,#语速
      'pit':8,#语音音调,
      'per':4,#发音人选择，
  })
  if not isinstance(result,dict):
      with open("answer.mp3",'wb') as f:
          f.write(result)
  else:
      print(result)#发生错误会打印错误
  
  #播放
  os.system('answer.mp3')
  ```

### 4.图灵机器人：

```python
http://www.turingapi.com/
用户名：13589306703
密码：xjk123456.
```

- 图灵机器人:

```python
tl_url = "http://openapi.tuling123.com/openapi/api/v2"

import requests

tl_data = {
    "perception": {
        "inputText": {
            "text": "你叫什么名字"
        }
    },
    "userInfo": {
        "apiKey": "51ff3d2dd9464ba6bba97ff1bb9427ab",
        "userId": "123456789123"
    }
}

res = requests.post(tl_url,json=tl_data)

res_json = res.json()
print(res_json)
print(res_json.get("results")[0].get("values").get("text"))
```

- resposne信息:

```python
{
	'emotion': {
		'robotEmotion': {
			'a': 0,
			'd': 0,
			'emotionId': 0,
			'p': 0
		},
		'userEmotion': {
			'a': 0,
			'd': 0,
			'emotionId': 0,
			'p': 0
		}
	},
	'intent': {
		'actionName': '',
		'code': 10004,
		'intentName': ''
	},
	'results': [{
		'groupType': 1,
		'resultType': 'text',
		'values': {
			'text': '我的名字叫小江儿，认识你很高兴呢！'
		}
	}]
}
```



#### 完整自动回复机器人（结合图灵机器人）

- 代码如下

  ```python
  import subprocess
  
  from aip import AipSpeech,AipNlp
  
   # 语音转文本  TTS技术
  import os
  
  """ 你的 APPID AK SK  获得百度云接口"""
  APP_ID = '16981704'
  API_KEY = 'CeLs5zCuQwWXBhHbrnDGQhc3'
  SECRET_KEY = 'HIOyvsDRcXKlP95NOY72CAUznUIC6OKZ'
  
  client = AipSpeech(APP_ID, API_KEY, SECRET_KEY)   # 获取到接口，将用于我们上传语音文本
  nlp_client = AipNlp(APP_ID, API_KEY, SECRET_KEY)  # 文本相似度查询接口
  
   #读取文本
  def get_file_content(filePath):
      cmd = f"ffmpeg -y  -i {filePath} -acodec pcm_s16le -f s16le -ac 1 -ar 16000 {filePath}.pcm"  # 将传入的格式转换为pcm
      # r = subprocess.Popen(cmd,shell=True,stdout=subprocess.PIPE,stderr=subprocess.PIPE,)  # 此方法是异步的
      # stdout = r.stdout.read().decode('gbk')
      # print(stdout)
      # stderr =  r.stderr.read().decode('gbk')
      # print(stderr)
  
      os.system(cmd)  #将录音转换格式
      try:
          with open(f"{filePath}.pcm", 'rb') as fp:
              return fp.read()  #发送的是字节流
      finally:
          os.remove(filePath)
   # 识别本地文件并发送，最后接受返回值
  res = client.asr(get_file_content('jxh.m4a'), 'pcm', 16000, {
      'dev_pid': 1536,
  })
  
  
  
  print(res)
  print(res.get("result")[0])
  
  Q = res.get("result")[0]  #读取出我们的问题
  
  A = "我不知道你在说什么"
  if nlp_client.simnet(Q,"你的名字叫什么").get("score") >= 0.6: # 文本相似度比较,自定义的问题
      A = "我叫小猪武沛齐,哼哼哼"
  else:
      tl_url = "http://openapi.tuling123.com/openapi/api/v2"  #获取到问答机器人接口
  
      import requests  #使用reqeust进行访问
  
      tl_data = {
          "perception": {
              "inputText": {
                  "text": "北京今天天气怎么样"
              }
          },
          "userInfo": {
              "apiKey": "51ff3d2dd9464ba6bba97ff1bb9427ab",
              "userId": "123456789123"
          }
      }
  
      tl_data["perception"]["inputText"]["text"] = Q  #替换问题
  
      res = requests.post(tl_url, json=tl_data)  #提交json格式的数据，到指定接口
  
      res_json = res.json()  #获取json格式的回答
      A = res_json.get("results")[0].get("values").get("text")
  
  print(A)
  
  result = client.synthesis(A, 'zh', 1,  #使用语音合成技术，生成音频ASR
                            {
                                'vol': 5,
                                "spd": 4,
                                "pit": 6,
                                "per": 4
                            })
  
   # 识别正确返回语音二进制 错误则返回dict 参照下面错误码
  if not isinstance(result, dict):
      with open('Answer.mp3', 'wb') as f:
          f.write(result)
  else:
      print(result)
  
  if 'Answer.mp3' in os.listdir():
      os.system("ffplay Answer.mp3")  #播放音乐
  
  ```

  